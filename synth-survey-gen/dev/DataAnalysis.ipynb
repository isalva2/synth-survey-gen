{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b467200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from preprocess import process_MyDailyTravelData\n",
    "\n",
    "survey_path = Path(\"../configs/Chicago/data/person.csv\")\n",
    "synth_path = Path(\"../run/acer_runs/Chicago_20250518_1525/20250518_1525_results.csv\")\n",
    "config_folder = Path(\"../configs/Chicago\")\n",
    "\n",
    "survey_df = pd.read_csv(survey_path, low_memory=False)\n",
    "synth_df = pd.read_csv(synth_path, index_col=0)\n",
    "query_dict = process_MyDailyTravelData(config_folder=config_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "respondent_columns = synth_df.columns[~synth_df.isna().all()].tolist()\n",
    "true_cols = [col for col in respondent_columns if col in survey_df.columns]\n",
    "true_df = survey_df[true_cols]\n",
    "gen_df = synth_df[respondent_columns]\n",
    "\n",
    "dtype_map = {}\n",
    "response_map = {}\n",
    "for col in true_cols:\n",
    "    capCol = col.upper()\n",
    "    try:\n",
    "        dtype_map[col] = query_dict[capCol][\"dtype\"]\n",
    "        response_map[col] = query_dict[capCol][\"response\"]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def convert_or_nan(df, cols, target_type=int, return_transposed_removed=False):\n",
    "    \"\"\"\n",
    "    Attempts to convert specified columns to a target type.\n",
    "    Replaces unconvertible values with NaN.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        cols (list): Columns to attempt conversion on.\n",
    "        target_type (type): Type to convert to (default is int).\n",
    "        return_transposed_removed (bool): If True, transposes the removed_df.\n",
    "\n",
    "    Returns:\n",
    "        cleaned_df (pd.DataFrame): DataFrame with conversions applied; unconvertible values become NaN.\n",
    "        removed_df (pd.DataFrame): Same shape as df[cols], showing which values failed conversion.\n",
    "        failure_counts (pd.Series): Number of failed conversions per column.\n",
    "    \"\"\"\n",
    "    cleaned_df = df.copy()\n",
    "    removed_data = pd.DataFrame(index=df.index, columns=cols)\n",
    "\n",
    "    for col in cols:\n",
    "        def try_convert(val):\n",
    "            if pd.isna(val) or isinstance(val, target_type):\n",
    "                return val\n",
    "            try:\n",
    "                return target_type(val)\n",
    "            except (ValueError, TypeError):\n",
    "                return np.nan\n",
    "\n",
    "        converted_col = df[col].apply(try_convert)\n",
    "        failed_mask = ~df[col].apply(lambda x: pd.isna(x) or isinstance(x, target_type) or _is_convertible(x, target_type))\n",
    "\n",
    "        cleaned_df[col] = converted_col\n",
    "        removed_data[col] = df[col].where(failed_mask)  # keep only failed conversions\n",
    "\n",
    "    failure_counts = removed_data.notna().sum()\n",
    "\n",
    "    removed_data = removed_data.dropna(how=\"all\")\n",
    "\n",
    "    if return_transposed_removed:\n",
    "        removed_data = removed_data.transpose()\n",
    "\n",
    "    return cleaned_df, removed_data, failure_counts\n",
    "\n",
    "\n",
    "def _is_convertible(val, target_type):\n",
    "    try:\n",
    "        target_type(val)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "int_cols = ['age', 'sex', 'lic', 'hisp', 'race',\n",
    "            'smrtphn', 'jobs', 'wkstat', 'wplace',\n",
    "            'wmode', 'wparkride', 'pervh', 'wrkhrs', 'wtrav', # wmode debateable for now\n",
    "            'occup', 'indus', 'emply_transit',\n",
    "            'emply_park', 'carptowk', 'tcoff', 'disab', 'dtype_o',\n",
    "            'dtype2', 'traveldatadevice'\n",
    "            ]\n",
    "\n",
    "clean, removed, counts = convert_or_nan(gen_df, int_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43843d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in true_cols:\n",
    "    question = query_dict[col.upper()][\"question\"]\n",
    "    print(f\"{col}: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def compare_pie_charts_with_mapping(df1, df2, col):\n",
    "    mapping = response_map[col]\n",
    "\n",
    "    # Filter df1 where col > 0\n",
    "    df1_filtered = df1[df1[col] > 0]\n",
    "\n",
    "    # Map values using provided dictionary\n",
    "    df1_mapped = df1_filtered[col].map(mapping).value_counts()\n",
    "    df2_mapped = df2[col].map(mapping).value_counts()\n",
    "\n",
    "    # Align indices (ensure same label order)\n",
    "    all_labels = sorted(set(df1_mapped.index).union(df2_mapped.index))\n",
    "    df1_mapped = df1_mapped.reindex(all_labels, fill_value=0)\n",
    "    df2_mapped = df2_mapped.reindex(all_labels, fill_value=0)\n",
    "\n",
    "    # Generate color palette dynamically\n",
    "    num_categories = len(all_labels)\n",
    "    if num_categories <= 10:\n",
    "        palette = sns.color_palette(\"tab10\", num_categories)\n",
    "    elif num_categories <= 20:\n",
    "        palette = sns.color_palette(\"tab20\", num_categories)\n",
    "    else:\n",
    "        cmap = plt.get_cmap('tab20c')  # Or 'hsv', 'nipy_spectral', etc.\n",
    "        palette = [cmap(i / num_categories) for i in range(num_categories)]\n",
    "\n",
    "    # Create side-by-side subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    wedges1, texts1, autotexts1 = axes[0].pie(\n",
    "        df1_mapped,\n",
    "        labels=None,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=140,\n",
    "        pctdistance=0.85,\n",
    "        labeldistance=1.1,\n",
    "        colors=palette\n",
    "    )\n",
    "    axes[0].set_title(f'True Data ({col} > 0)')\n",
    "    axes[0].axis('equal')\n",
    "\n",
    "    wedges2, texts2, autotexts2 = axes[1].pie(\n",
    "        df2_mapped,\n",
    "        labels=None,\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=140,\n",
    "        pctdistance=0.85,\n",
    "        labeldistance=1.1,\n",
    "        colors=palette\n",
    "    )\n",
    "    axes[1].set_title(f'Synthetic Data')\n",
    "    axes[1].axis('equal')\n",
    "\n",
    "    # Create one legend for both charts\n",
    "    fig.legend(wedges1, all_labels, title=col, loc='center right', bbox_to_anchor=(1.15, 0.5), fontsize='medium')\n",
    "\n",
    "    question = query_dict[col.upper()][\"question\"]\n",
    "    fig.suptitle(f\"Survey Question: {question}\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to fit legend\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "compare_pie_charts_with_mapping(true_df, clean, \"wmode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de655ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in int_cols:\n",
    "    try:\n",
    "        compare_pie_charts_with_mapping(true_df, clean, col)\n",
    "    except:\n",
    "        print(f\"{col} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ebd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_kde_plots(df1, df2, col, show_hist=False):\n",
    "    # Filter out non-positive values\n",
    "    df1_filtered = df1[df1[col] > 0]\n",
    "    df2_filtered = df2[df2[col] > 0]\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot KDE and optional histogram\n",
    "    sns.kdeplot(df1_filtered[col].dropna(), label='True Data', fill=True, alpha=0.4)\n",
    "    sns.kdeplot(df2_filtered[col].dropna(), label='Synthetic Data', fill=True, alpha=0.4)\n",
    "\n",
    "    if show_hist:\n",
    "        sns.histplot(df1_filtered[col].dropna(), bins=30, kde=False, stat=\"density\", color='blue', alpha=0.3, label='True Data (hist)')\n",
    "        sns.histplot(df2_filtered[col].dropna(), bins=30, kde=False, stat=\"density\", color='orange', alpha=0.3, label='Synthetic Data (hist)')\n",
    "\n",
    "    # Title and labels\n",
    "    plt.title(f\"Survey Question: {query_dict.get(col.upper(), {}).get('question', col)}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_kde_plots(true_df, clean, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_vars = [\n",
    "    \"age\",\n",
    "    \"jobs\",\n",
    "    \"wrkhrs\",\n",
    "    \"wtrav\",\n",
    "    \"carptowk\"\n",
    "]\n",
    "\n",
    "hist_flag = [False, True, False, True, True]\n",
    "\n",
    "for flag, var in zip(hist_flag, continuous_vars):\n",
    "    compare_kde_plots(true_df, clean, var, show)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
