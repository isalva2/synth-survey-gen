{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "LLM Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking questions: 100%|██████████| 3/3 [00:01<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from synthesize import read_config, survey_agent, run_survey, dummy_chat\n",
    "import ollama\n",
    "from ollama import chat, ChatResponse\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "model_conf, questions = read_config(config_folder=\"configs/test_config\")\n",
    "\n",
    "test_prompt = \"Your name is {}. You are a {} year old {} living in {} County, Illinois. You are middles class. Please think in your head about your life, memories, and day-to-day activities. In a moment we will be conducting a survey, please answer to the best of your ability. Please answer per the provided instructions in the format 'number: response'. No further elaboration is neccessary and please try not to skip answers.\"\n",
    "test_attrs = [\n",
    "    \"Jennifer Wilson\",\n",
    "    \"36\",\n",
    "    \"woman\",\n",
    "    \"Will\"\n",
    "]\n",
    "\n",
    "my_agent = survey_agent(0, test_prompt, test_attrs)\n",
    "agents = [my_agent]\n",
    "\n",
    "model_name = model_conf[\"model_name\"]\n",
    "model_parameters = model_conf[\"model_params\"]\n",
    "\n",
    "run_survey(agents, model_conf, questions, max_q=3, truncate_memory=False)\n",
    "\n",
    "# for agent in agents:\n",
    "#     for key in tqdm(list(questions.keys())[:20]):\n",
    "#         survey_question = questions[key][\"question\"]\n",
    "#         possible_responses = \"; \".join(f\"{k}: {v}\" for k, v in questions[key][\"response\"].items())\n",
    "\n",
    "#         chat_question = {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": f\"{survey_question} Please respond in the format 'number: option'. Possible choices are {possible_responses}\"\n",
    "#             }\n",
    "#         chat_message = copy.deepcopy(agent.messages)\n",
    "#         chat_message.append(chat_question)\n",
    "\n",
    "#         agent.record_question(survey_question)\n",
    "\n",
    "#         response: ChatResponse = ollama.chat(\n",
    "#             model = model_name,\n",
    "#             options = model_parameters,\n",
    "#             messages = chat_message,\n",
    "#             stream=False\n",
    "#         )\n",
    "\n",
    "#         assistant_content = response[\"message\"][\"content\"]\n",
    "#         agent.record_response(assistant_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a sweet question! As a machine, I don't have the capacity to love or feel emotions in the way that humans do. My purpose is to provide information, answer questions, and assist with tasks to the best of my abilities, but I don't have personal feelings or emotions.\\n\\nHowever, I'm designed to be helpful and supportive, and I want you to know that I'm here for you! If you need assistance, advice, or just someone to talk to, I'm here to listen and help in any way I can.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyChat = dummy_chat(model_conf)\n",
    "\n",
    "MyChat.chat(\"Hi how are you\")\n",
    "MyChat.chat(\"Do you love me\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi how are you',\n",
       " \"I'm just a computer program, so I don't have feelings or emotions like humans do, but thanks for asking! How can I assist you today?\",\n",
       " 'Do you love me',\n",
       " \"That's a sweet question! As a machine, I don't have the capacity to love or feel emotions in the way that humans do. My purpose is to provide information, answer questions, and assist with tasks to the best of my abilities, but I don't have personal feelings or emotions.\\n\\nHowever, I'm designed to be helpful and supportive, and I want you to know that I'm here for you! If you need assistance, advice, or just someone to talk to, I'm here to listen and help in any way I can.\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyChat.chat_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: '1: Yes, I am 18 or older.' -> Output: 1\n",
      "Input: '-42: This is a negative number.' -> Output: -42\n",
      "Input: '  7  : Some text here.' -> Output: 7\n",
      "Input: 'No number here:' -> Output: None\n",
      "Input: '100: Valid format' -> Output: 100\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_number(input_string):\n",
    "    match = re.match(r'^\\s*(-?\\d+)\\s*:\\s*(.+)', input_string)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "test_strings = [\n",
    "    \"1: Yes, I am 18 or older.\",\n",
    "    \"-42: This is a negative number.\",\n",
    "    \"  7  : Some text here.\",\n",
    "    \"No number here:\",\n",
    "    \"100: Valid format\"\n",
    "]\n",
    "\n",
    "for s in test_strings:\n",
    "    print(f\"Input: {s!r} -> Output: {extract_number(s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "5\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "None\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "1\n",
      "40\n",
      "3\n",
      "43\n",
      "None\n",
      "56\n",
      "None\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "-1\n",
      "2\n",
      "2\n",
      "-1\n",
      "2\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "2\n",
      "2\n",
      "-1\n",
      "-1\n",
      "2\n",
      "2\n",
      "-1\n",
      "-1\n",
      "2\n",
      "2\n",
      "2\n",
      "-1\n",
      "2\n",
      "2\n",
      "-1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-9\n",
      "-1\n",
      "-9\n",
      "-9\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "-1\n",
      "-9\n",
      "-9\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-9\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "for response in agents[0].survey_responses:\n",
    "    print(extract_number(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
