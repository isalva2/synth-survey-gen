# A Perspective on Large Language Model (LLM) Applications in the Transportation Research Space
Researchers in transportation face a core challenge: how to represent the travel decisions of individuals, often diverse and unpredictable, while building models that are useful at larger, collective scales. On one side, there is the need to account for the complexity and sometimes non-linear logic of individual behavior. On the other, these behaviors must be expressed through simplified rules, assumptions, and inputs that allow models to remain analytically and computationally manageable. These simplifications are necessary for practical reasons, but they can leave out important aspects of how people actually make travel choices. This raises an important question: to what extent can human travel decisions be meaningfully represented through abstraction? Moving forward, there is an opportunity to design approaches that more directly reflect the richness of individual behavior, rather than only smoothing it into system-level averages.

One promising direction is the use of Large Language Models (LLMs) as simulated travelers or agents within travel behavior modeling. Current applications of LLMs in transportation tend to be limited, often using them as predictors or domain experts that provide forecasts or high-level insights. These uses do not go far beyond what other machine learning tools already offer. In contrast, LLM-based agents can represent individual travelers more dynamically. They can reason through multi-step decisions, maintain internal states, interact with external tools, and respond to changing contexts. Unlike traditional agent-based modeling approaches, they are not constrained by fixed heuristics or rule sets, which allows them to capture a wider range of possible behaviors. Instead of describing behavior from a top-down perspective, these agents can act within a simulated environment as if they were travelers themselves. This approach better reflects the way travel decisions emerge at the individual level, while still offering a pathway to study patterns that matter at the system scale.

## What is Travel Behavior?

Travel behavior is the way that individuals and households adapt their activity and travel patterns to meet their needs needs and desires. These activity and patterns arise from constraints derived from available opportunities, and are shaped by the geographic location and distribution of activity sites and transportation systems. Complex travel behavior can be attributed to social, demographic, and spatial factors, and these factors not only influence daily, small-scale activity, but also major changes such as residence or work location [1](https://trid.trb.org/View/55954). Research in this area arose in response to dissatisfaction over the shortcomings of trip-based travel demand models, with the activity-based model capturing finer temporal and spatial granularity. In particular, trip-based models strictly adhere to utility maximization, neglecting the the household interrelationships, choice complexity, habit formation, and other complex factors that that comprise travel behavior [2](https://www.sciencedirect.com/science/article/pii/0191260786900890).

Indeed, much more than socio-demographic profiles and spatial locations goes into the long and short-term decision making that constitutes travel behavior. To this end, researchers have proposed several frameworks that incorporate more abstract components of travel behavior decision making. For example, Van Acker et al. developed a conceptual model of travel behavior that integrates an activity based approach with social psychology, utilizing the theories of planned behavior and repeated behavior. The model takes into account "lifestyle", "perceptions", "attitudes", and "preferences" as key-variables that indirectly influence travel behavior [3](https://www.researchgate.net/publication/233327533_When_Transport_Geography_Meets_Social_Psychology_Toward_a_Conceptual_Model_of_Travel_Behaviour). The Process and Determinants of Mobility Decisions (PDMD) framework, introduced by López and Wong, further elaborate on this, noting that psychological limitations related to perception, values, and attitudes hold as much weight as physical limitations of travel behavior constrained by geographic contexts [4](https://www.sciencedirect.com/science/article/pii/S2214367X18301388#b0170).

## How Do We Capture Travel Behavior?

In the United States, the National Household Travel Survey (NHTS) serves as the primary source of nationwide travel behavior data. Conducted periodically by the Federal Highway Administration (FHWA), the NHTS captures detailed information on daily travel patterns, including trip purpose, mode, time of day, and household demographics. At the regional level, more granular surveys are often conducted to better reflect local travel behavior. For example, the Chicago Metropolitan Agency for Planning (CMAP) conducted the My Daily Travel Survey in 2019 to gather comprehensive travel within the greater Chicagoland area. This survey builds upon the NHTS framework by including questions relevant to travel in northeastern Illinois and conducting a larger sample size for the region.

Stopher and Greaves note that in the early days of transportation planning, travel survey sample sizes were often as large as one to three percent, but they had dropped to less than half a percent by 2006 [5](https://www.researchgate.net/publication/23526726_Household_travel_surveys_Where_are_we_going). Extrapolating these findings to the Chicago My Daily Travel, the latest iterations report a sample rate of 0.04\% [6](https://cmap.illinois.gov/news-updates/my-daily-travel-survey-underway-this-fall/). These sample rates can also fluctuate by region, the authors of the Chicago Area Transportation Survey (CATS), a precursor to the current My Daily Travel survey, discussed that while the total sample rate of the survey was only 0.73\% throughout the northeastern region of Illinois, the majority of the City of Chicago was sampled at a rate of 0.22\% of the population [7](https://www.icpsr.umich.edu/web/ICPSR/studies/34908).

Underrepresentation and survey quality issues compound even further for developing countries and low-income populations. For example, the 2012 household travel survey (HTS) conducted in Medellín, Columbia was comprised of 20,000 (2\% population sample) face-to-face interviews. An analysis of those results concluded a trip rate of 1.7 per inhabitant, a questionably low result [8](https://www.researchgate.net/publication/270208016_Important_Aspects_to_Consider_for_Household_Travel_Surveys_in_Developing_Countries). The HTS operators further noted that poor working conditions, traffic problems, irregular travel behavior (predominantly due to the FIFA U-20 World Cup at the time), and restricted access to high-income individuals in certain areas presented difficulties in the data collection process. Moswete and Darley [9](https://www.researchgate.net/publication/239790491_Tourism_Survey_Research_in_Sub-Saharan_Africa_Problems_and_Challenges) discuss similar issues with their research on HTS in sub-Saharan African countries and explain that due to the vast economic and cultural subgroups in these countries, further issues arise, leading to higher non-response rates. The researchers alluded to a rise in non-response rates when there were ethnic, gender, and age differences between the interviewer and respondent, and entire groups of people could be omitted from the survey collection process, pending approval from a village or family head.

Naturally, the US is not without these issues as well. Bills and Esekhaigbe [10](https://www.researchgate.net/publication/384180616_Group_Representation_of_Disadvantaged_Travelers_in_Household_Travel_Surveys_An_Assessment_of_43_US_surveys) reviewed 43 regional and state travel surveys in the US and discovered that many HTS underreported low-income, transit-dependent, unemployed, and minority ethnicized groups, with only 11 of the 43 reasonably representing these groups well, with 85\% of these surveys over-representing white travelers. The group suggests that using an exogenous income and race-based sampling method, combining GPS and phone data retrieval modes, and offering higher incentives for hard-to-reach survey participants can better represent these disadvantaged groups.

## The Big Issue

Despite the issues present in HTS, they remain a quintessential data source for travel behavior research and a mandatory input for downstream research applications, namely activity-based travel demand modeling [11](https://www.tandfonline.com/doi/full/10.1080/01441647.2023.2198458). Activity-based models of travel behavior aim to simulate travel as a derived demand from individuals’ participation in daily activities, rather than treating trips as independent events. These models, particularly in their advanced activity-scheduling form, explicitly generate activity episodes with defined types, start times, durations, and locations, allowing trips to emerge organically as part of continuous daily patterns. While theoretically more flexible and behaviorally realistic than traditional tour-based models, activity-based models face significant limitations, especially in capturing atypical or unordinary events. Their reliance on historical travel survey data and fixed behavioral assumptions makes it difficult to account for sudden changes in travel behavior, such as those induced by pandemics, extreme weather, or other disruptive societal shifts.

Combined with the infrequency, low penetration, and high costs of their requisite travel survey inputs, activity-based travel demand models are constrained to largely reproducing historical patterns rather than dynamically predicting future behaviors. This limitation becomes particularly salient when attempting to understand emergent travel trends, such as shifts in commuting patterns due to telework, adoption of micromobility options, or the impacts of major policy interventions. In contrast, LLM agents, autonomous, heterogeneous entities powered by LLMs that are capable of reasoning over multiple steps, maintaining internal state, and using external tools, offer a more compelling paradigm.

Transportation researchers have so far largely adopted LLMs in a limited capacity, often treating these large models as black-box predictors or domain experts that provide high-level insights or demand forecasts. This use treats LLMs as static tools, relegated to analysis applications that lack behavioral nuance and do little more than what simpler, faster, machine learning models can already achieve. Tasks like demand forecasting, trip classification, or mode choice prediction have long been addressed using conventional models such as decision trees, random forests, or gradient boosting [12](https://journals.sagepub.com/doi/10.1177/0361198118796971), [13](https://www.nature.com/articles/s44333-024-00022-4). Applying LLMs to these problems without leveraging their unique strengths leads to unnecessary complexity and computational cost.

## The Proposed Solution: LLM-based Travel Behavior Agents

Rather than asking an LLM to describe or predict travel behavior from a top-down, system-wide perspective, an LLM agent can inhabit the role of a traveler, responding to travel behavior research objectives as a simulated individual making travel decisions within a defined context. The approach more naturally aligns with the behavioral structure of traveling individuals and offers a way to generate synthetic data that is not only context aware, but also behaviorally rich and responsive to scenario variation. Leveraging LLMs in this agent-based way may yield more accurate, transparent, and adaptable synthetic travel data, especially for regions facing constraints in traditional data collection.

While LLMs have found application in the transportation research space, their use has remained relatively narrow and underutilized. Most studies approach LLMs in passive, analysis oriented-oriented roles. These applications broadly fall into the categories of traffic forecasting, human mobility, demand forecasting, and missing data imputation [14](https://arxiv.org/abs/2405.02357). For example, Guo et al. [15](https://arxiv.org/abs/2404.02937) developed a traffic flow prediction model by converting multi-modal traffic data into natural language descriptions. This model incorporates the open-source Llama2 foundational model. It uses a fusion of spatial information, historical traffic volumes, date and special-event contexts, and weather information to generate a traffic prediction and text explanation of the prediction. Chen et al. [16](https://arxiv.org/abs/2311.14332) integrated the GPT-2 model in a regression framework to impute missing traffic data by combining spatiotemporal sensor data and time-series traffic flow data in an embedded format that LLMs can easily process. Most pertinent to this research, Xu et al. [17](https://arxiv.org/abs/2312.00819) developed a zero-shot prompting framework that leverages GPT-3.5 to predict travel behavior such as mode choice and trip purpose without requiring any training data. They demonstrate that their approach delivers competitive performance compared to traditional models like multinomial logit, random forest, and neural networks, particularly in data-scarce situations, while also providing interpretable reasoning behind predictions.

Current approaches continue to underutilize the generative strengths of LLMs, often embedding them as static components within larger modeling frameworks or prompting them from the perspective of a domain expert or helpful assistant. These roles, while convenient for analysis or interpretability, limit the model’s potential to simulate behavior in a dynamic, context-aware manner. Treating the model as a narrator or regression tool strips away its capacity to act as an agent, one capable of making decisions, adapting to inputs, and generating outputs reflective of individual-level variability. This framing overlooks the behavioral richness that LLMs can offer when prompted from the bottom up, as a traveler embedded within a specific demographic and geographic profile. In response to the considerations of the current activity-based modeling paradigm and the gap in application of LLMs in this field, this article proposes the application of LLM-based agents as a viable alternative to study travel behavior. Rather than relying on the socio-demographic and spatiotemporal variables essential to contemporary approaches, this perspective exposes the opportunity to include psychological and behavioral dimensions, such habitual tendencies, tendencies towards risk, and subjective preferences, that have been acknowledged as influential in the travel decision making process but remain difficult to operationalize in conventional models.



## What are Large Language Models?

Large language models are a class of machine learning models designed to generate text. As the name suggests, they are a type of language model whose primary purpose is to capture the probability distribution of natural language. This probability is expressed by the chain rule of probability:

$$
P(W) = P(w_1,w_2,\ldots,w_N) = \prod_{i}P(w_i\mid w_1,w_2,\ldots w_{i-1})
$$

where for a sequence of words, $W = w_1,\ldots,w_N$, a language model estimates the joint probability of this sequence occurring, $P(W)$. LLMs extend this prediction from words to the token level, where a token can instead represent a word, sub-word, or special characters such as punctuations or end-of-statement markers. These tokens serve as input for the transformer architecture, the dominant LLM architecture introduced by Vaswani et al [18](http://arxiv.org/abs/1706.03762). For each token, an attention score is computed for every token in the input sequence (including itself) as:

$$
\text{Attention}(Q, K, V) = \text{softmax} \left(\frac{QK^T}{\sqrt{d_k}} \right)V
$$

where $\textit{Q}$, $\textit{K}$, and $\textit{V}$ are query, key, and value vectors, derived from learned representations of each token in a sequence. The softmax function converts the scaled dot product $QK^T$ into attention weights. These attention weights are used to compute the weighted sum of $\textit{V}$, the actual output of the attention mechanism. These models are trained on a corpus of text training data, which involves optimizing model parameters to accurately predict tokens in a sequence. Bengio et al. [19](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) proposed the use of maximum likelihood estimation to obtain the optimal model parameters, $\theta$:

$$
\mathcal{L}=\sum_{i}\log P(w_i|w_1,\ldots, w_{i-1}; \theta)
$$

And despite the formulation's initial application to language models over 20 years ago, variants of MLE remain the primary training mechanism for the latest generations of LLMs, which are comprised of billions or even trillions of parameters. Contemporary models are trained on trillions of tokens obtained from books, articles, source code, and text from the public web [20,](https://arxiv.org/pdf/2005.14165) [21](https://arxiv.org/abs/2303.08774).

The final step in the construction of an LLM consists of post-training routines to align models with human intent and establish safety considerations. The most common method uses supervised fine-tuning (SFT) on high-quality datasets, followed by reinforcement learning from human feedback (RLHF). This process involves human interlocutors ranking model outputs to form a reward model, from which LLMs can learn preferred response behavior [22,](https://arxiv.org/abs/1909.08593) [22,](https://arxiv.org/abs/2203.02155). These alignment techniques control behaviors such as truthfulness, coherence, and safety. These large-scale models are colloquially known as foundation models [23](https://hai.stanford.edu/news/introducing-center-research-foundation-models-crfm), which can be adapted to a wide range of downstream applications with minimal task-specific modifications.

## The Effectiveness and Application of Large Language Models

emergent properties arise that make LLMs notably effective both in and out of an autonomous agent context. One of the most significant properties is few-shot learning, the ability to generalize from a handful of examples provided to the LLM at inference time without any additional context or training. Furthermore, Kojima et al. [19](http://arxiv.org/abs/2205.11916) note the performance of zero-shot reasoning, where models infer solutions to complex problems, enabled by patterns absorbed during model training. Finally, chain-of-though (CoT) prompting has emerged as a powerful method for improving reasoning. Wei et al. [20](https://arxiv.org/abs/2203.02155) noted that by encouraging models to generate intermediate steps towards a solution, analogous human logical reasoning, CoT significantly improves performance on tasks that require multiple steps, arithmetic, or commonsense logic. Given these emergent reasoning capabilities, LLMs offer a compelling foundation for building autonomous agents that prioritizes human-like planning and adaptability.

In deployed systems, LLMs are typically accessed through cloud-based application programming interfaces (APIs), where they serve as the computational engine behind applications like chatbots, assistants, and domain-specific agents. These interactions are often mediated by an initial system prompt, a block of instructions or context provided before the user ever inputs a message. This prompt sets the behavioral tone, constraints, and intended capabilities of the model, shaping its responses throughout the session. For example, a system prompt might instruct the model to “act as a helpful transportation researcher,” “avoid speculation,” or “respond in concise bullet points.” Despite the appearance of dialogue, LLMs do not possess intent, beliefs, or understanding in any human sense. As Bommasani et al. [24](https://www.nature.com/articles/s41586-023-06647-8) emphasize, LLMs operate as statistical pattern matchers—generating sequences of text by predicting the most likely next token, conditioned on the prompt and prior inputs. The illusion of coherent personality or reasoning stems from scale, not cognition. It is crucial, especially in scientific applications, not to conflate fluency with fidelity. While LLMs can emulate decision-making behavior when configured appropriately, they remain tools that simulate reasoning rather than entities that perform it.

## The Characteristics of LLM-based Travel Behavior Agents

As the name suggests, LLM-based Travel Behavior Agents are a subset of LLM-based autonomous agents, designed to achieve specified objectives through self-guided instructions. Where this method excels over previous studies is, unlike heuristic-based or reinforcement learning (RL) regimes, LLM-based agents posses a more comprehensive internal world knowledge, allowing for informed actions and decision making without training on domain-specific data [25](https://arxiv.org/pdf/2308.11432).

# Potential LLM-based Travel Behavior Applications

- Travel Survey Data Generation
- Activity Selection, discretionary activities
  - Travel Demand models struggle to select discretionary activities
  - Retrieval Augemented Generation (RAG) agent attached to activity location database serves as an agent's internal preferences on locations for shopping, leisure activities, etc.
- Intrapersonal interaction and decision making
  - Household and societal agent interaction using human language to plan, prioritize, and compromise on activity planning.
- Long-term decision making

# Considerations LLM Approach
 - Agent alignment and bias
    - Alignment of regional preferences and algorithmic bias in LLM decision making
 - The dataset conondrum
   - Transportation data makes up a miniscule part of foundation model training corpuses.
 - Ethical considerations
 -